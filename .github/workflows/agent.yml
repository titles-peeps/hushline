name: run-agent

on:
  issues:
    types: [labeled]

jobs:
  run:
    if: contains(github.event.label.name, 'run-agent')
    runs-on: self-hosted

    env:
      GH_TOKEN: ${{ secrets.AGENT_TOKEN }}
      # Talk directly to local Ollama:
      OLLAMA_API_BASE: http://127.0.0.1:11434
      # IMPORTANT: use the SLASH form so Aider uses native Ollama client
      AIDER_MODEL: ollama_chat/qwen2.5-coder:7b-instruct

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Show runner basics
        run: |
          echo "Runner: $(uname -a)"
          echo "Python: $(python3 -V || true)"
          echo "Ollama API: ${OLLAMA_API_BASE}"

      - name: Warm up Ollama (pull model if missing)
        shell: bash
        run: |
          set -euo pipefail
          curl -fsS "$OLLAMA_API_BASE/api/tags" | jq -r '.models[].name' || true
          if ! curl -fsS "$OLLAMA_API_BASE/api/tags" \
             | jq -e --arg m "$(echo '${{ env.AIDER_MODEL }}' | sed 's#.*[/]\(.*\)#\1#')" \
                  '.models[].name | contains($m)' >/dev/null; then
            plain="$(echo '${{ env.AIDER_MODEL }}' | sed 's#.*[/]\(.*\)#\1#')"
            echo "Pulling model: $plain"
            curl -fsS "$OLLAMA_API_BASE/api/pull" \
              -H 'Content-Type: application/json' \
              -d "{\"model\":\"$plain\"}"
          fi

      - name: Run agent
        shell: bash
        env:
          ISSUE_NUM: ${{ github.event.issue.number }}
        run: |
          set -euo pipefail
          bash ops/agent.sh "$ISSUE_NUM"
