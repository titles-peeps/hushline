name: run-agent

on:
  issues:
    types: [labeled]
  workflow_dispatch:
    inputs:
      issue:
        description: Issue number
        required: true
        type: string

jobs:
  agent:
    if: >
      (github.event_name == 'issues' && github.event.label.name == 'agent') ||
      (github.event_name == 'workflow_dispatch')
    runs-on: self-hosted

    env:
      GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      OLLAMA_API_BASE: http://127.0.0.1:11434
      # Force aider/LiteLLM to the Ollama backend
      LITELLM_PROVIDER: ollama
      # Optional: silence the model warning spam
      AIDER_MODEL: ollama:qwen2.5-coder:7b-instruct

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Warm up Ollama model (best-effort)
        run: |
          set -e
          curl -fsS "$OLLAMA_API_BASE/api/tags" | jq . >/dev/null || exit 0
          curl -fsS -X POST "$OLLAMA_API_BASE/api/pull" \
            -H 'Content-Type: application/json' \
            -d '{"model":"qwen2.5-coder:7b-instruct"}' || true

      - name: Run agent
        env:
          ISSUE_NUM: ${{ github.event_name == 'workflow_dispatch' && inputs.issue || github.event.issue.number }}
        run: |
          bash ops/agent.sh "$ISSUE_NUM"
